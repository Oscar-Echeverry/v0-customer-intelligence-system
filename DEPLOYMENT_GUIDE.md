# ğŸš€ GuÃ­a de Despliegue - Customer Intelligence System

## Arquitectura del Sistema

\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Next.js Frontend  â”‚  Puerto 3000
â”‚   (Vercel/Local)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ HTTP Requests
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Next.js API       â”‚  /api/v1/predict/lead-quality
â”‚   Routes            â”‚  /api/v1/churn/at-risk
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ HTTP POST
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Server     â”‚  Puerto 8000
â”‚  (Python ML)        â”‚  
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ joblib.load()
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Trained Models     â”‚  /ml/models/*.joblib
â”‚  (.joblib files)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

## ğŸ“‹ Pasos de Despliegue

### 1ï¸âƒ£ Entrenar los Modelos (Primero!)

\`\`\`bash
# Desde la raÃ­z del proyecto
python ml/train_leads_and_churn.py
\`\`\`

Esto generarÃ¡:
- `ml/models/lead_quality_model.joblib`
- `ml/models/lead_quality_scaler.joblib`
- `ml/models/feature_config_leads.json`
- `ml/models/churn_model.joblib`
- `ml/models/churn_scaler.joblib`
- `ml/models/feature_config_churn.json`

### 2ï¸âƒ£ Iniciar Servidor Python

**OpciÃ³n A: Script automÃ¡tico (recomendado)**

\`\`\`bash
chmod +x python-server/start-server.sh
./python-server/start-server.sh
\`\`\`

**OpciÃ³n B: Manual**

\`\`\`bash
cd python-server
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python main.py
\`\`\`

Verifica que estÃ© funcionando:
\`\`\`bash
curl http://localhost:8000/health
\`\`\`

### 3ï¸âƒ£ Configurar Variables de Entorno en Next.js

Crea o actualiza `.env.local`:

\`\`\`bash
# URL del servidor Python
PYTHON_SERVER_URL=http://localhost:8000

# Otras variables...
NEXT_PUBLIC_BASE_URL=http://localhost:3000
\`\`\`

### 4ï¸âƒ£ Iniciar Next.js

\`\`\`bash
npm install
npm run dev
\`\`\`

### 5ï¸âƒ£ Probar la IntegraciÃ³n

1. Ve a http://localhost:3000/bot
2. Completa el formulario del bot:
   - Nombre: "Test Lead"
   - Ciudad: "BogotÃ¡"
   - Presupuesto: 15000000
   - Urgencia: 4
   - Servicio: "Social Ads"
3. Verifica en la consola del servidor Python que reciba la peticiÃ³n
4. El bot debe mostrar la predicciÃ³n real del modelo

## ğŸ” VerificaciÃ³n del Sistema

### Test 1: Health Check del Servidor Python

\`\`\`bash
curl http://localhost:8000/health
\`\`\`

Respuesta esperada:
\`\`\`json
{
  "status": "healthy",
  "models": {
    "lead_quality": true,
    "churn": true
  }
}
\`\`\`

### Test 2: PredicciÃ³n Manual desde Terminal

\`\`\`bash
curl -X POST http://localhost:8000/predict/lead-quality \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Test Lead",
    "city": "BogotÃ¡",
    "budget": 15000000,
    "urgency": 4,
    "service_type": "Social Ads"
  }'
\`\`\`

### Test 3: Desde Next.js API Route

\`\`\`bash
curl -X POST http://localhost:3000/api/v1/predict/lead-quality \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Test Lead",
    "city": "BogotÃ¡",
    "budget": 15000000,
    "urgency": 4,
    "service_type": "Social Ads"
  }'
\`\`\`

## ğŸ› Troubleshooting

### Problema: "Connection refused" al Python server

**SoluciÃ³n:**
\`\`\`bash
# Verifica que el servidor Python estÃ© corriendo
ps aux | grep python

# Reinicia el servidor
./python-server/start-server.sh
\`\`\`

### Problema: "ModuleNotFoundError: No module named 'ml'"

**SoluciÃ³n:** El servidor Python debe ejecutarse desde la raÃ­z del proyecto:
\`\`\`bash
# âœ… Correcto
python python-server/main.py

# âŒ Incorrecto  
cd python-server && python main.py
\`\`\`

### Problema: "FileNotFoundError: Modelo no encontrado"

**SoluciÃ³n:** Entrena los modelos primero:
\`\`\`bash
python ml/train_leads_and_churn.py
ls -la ml/models/  # Verifica que los archivos existan
\`\`\`

### Problema: Next.js no se conecta al servidor Python

**SoluciÃ³n:** Verifica la variable de entorno:
\`\`\`bash
echo $PYTHON_SERVER_URL  # Debe ser http://localhost:8000
\`\`\`

## ğŸŒ Despliegue en ProducciÃ³n

### OpciÃ³n 1: Vercel + Railway

1. **Frontend (Vercel):**
   - Deploy Next.js a Vercel normalmente
   - Configura variable: `PYTHON_SERVER_URL=https://tu-app.railway.app`

2. **Backend Python (Railway):**
   - Crea cuenta en Railway.app
   - Deploy desde GitHub
   - Railway detectarÃ¡ `requirements.txt` automÃ¡ticamente
   - Configura Procfile:
     \`\`\`
     web: cd python-server && uvicorn main:app --host 0.0.0.0 --port $PORT
     \`\`\`

### OpciÃ³n 2: Todo en un VPS (DigitalOcean/AWS)

\`\`\`bash
# Instalar dependencias del sistema
sudo apt update
sudo apt install python3-pip nodejs npm

# Clonar repo y configurar
git clone <tu-repo>
cd customer-intelligence-system

# Setup Python
python3 -m venv venv
source venv/bin/activate
pip install -r python-server/requirements.txt
python ml/train_leads_and_churn.py

# Setup Next.js
npm install
npm run build

# Usar PM2 para mantener servicios corriendo
npm install -g pm2

# Iniciar Python server
pm2 start python-server/main.py --name ml-server --interpreter python3

# Iniciar Next.js
pm2 start npm --name nextjs -- start

# Configurar nginx como reverse proxy
\`\`\`

## ğŸ“Š Monitoreo

### Logs del Servidor Python

\`\`\`bash
tail -f python-server.log
\`\`\`

### Logs de Next.js

\`\`\`bash
npm run dev  # Modo desarrollo con logs en terminal
\`\`\`

### MÃ©tricas de Predicciones

Agrega logging en `python-server/main.py`:
\`\`\`python
import logging
logging.basicConfig(
    filename='predictions.log',
    level=logging.INFO,
    format='%(asctime)s - %(message)s'
)
\`\`\`

## âœ… Checklist de Despliegue

- [ ] Modelos entrenados en `/ml/models/`
- [ ] Servidor Python corriendo en puerto 8000
- [ ] Variable `PYTHON_SERVER_URL` configurada
- [ ] Next.js corriendo en puerto 3000
- [ ] Health check responde correctamente
- [ ] Bot funciona end-to-end
- [ ] Predicciones reales (no fallback)
- [ ] Logs monitoreados

## ğŸ¯ Flujo Completo de Trabajo

1. **Desarrollo Local:**
   - Terminal 1: `./python-server/start-server.sh`
   - Terminal 2: `npm run dev`
   - Navegar a http://localhost:3000/bot

2. **Testing:**
   - Probar bot con diferentes inputs
   - Verificar logs en ambos servidores
   - Confirmar que usa modelos reales

3. **Deploy:**
   - Push a GitHub
   - Deploy frontend a Vercel
   - Deploy backend a Railway/VPS
   - Configurar variables de entorno
   - Smoke test en producciÃ³n

**Â¡Sistema completamente integrado con ML real! ğŸ‰**
