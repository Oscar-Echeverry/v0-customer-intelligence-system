# ğŸ¤– MÃ³dulo de Machine Learning - Customer Intelligence System

Este mÃ³dulo contiene los scripts de entrenamiento y utilidades para los modelos de Machine Learning del sistema de inteligencia de clientes.

## ğŸ“Š Modelos Disponibles

### 1. Modelo de Calidad de Leads (Lead Scoring)

**Objetivo:** Clasificar leads en tres categorÃ­as (caliente, tibio, frÃ­o) segÃºn su probabilidad de convertirse en clientes de alta calidad.

**Features utilizadas:**
- `presupuesto_numeric`: Presupuesto del lead mapeado a valores numÃ©ricos (2.5M - 75M COP)
- `urgencia_numeric`: Nivel de urgencia del proyecto (1-4: Baja, Media, Alta, Inmediata)
- `tipo_servicio_encoded`: Tipo de servicio solicitado (ConsultorÃ­a, Desarrollo, Marketing, Infraestructura)
- `ciudad_encoded`: Ciudad del lead (BogotÃ¡, MedellÃ­n, Cali, Barranquilla, Cartagena, Bucaramanga)

**Algoritmos comparados:**
- Logistic Regression (baseline)
- Random Forest Classifier (configuraciÃ³n optimizada)

El script entrena ambos modelos y selecciona automÃ¡ticamente el de mejor rendimiento.

**Target:** ClasificaciÃ³n multi-clase
- ğŸ”¥ **Caliente** (Alta): Leads con alta probabilidad de conversiÃ³n
- ğŸŸ¡ **Tibio** (Media): Leads con probabilidad moderada
- ğŸ§Š **FrÃ­o** (Baja): Leads con baja probabilidad

**MÃ©tricas de evaluaciÃ³n:**
- Accuracy: PrecisiÃ³n general del modelo
- F1-Score (macro): Balance entre precisiÃ³n y recall para todas las clases
- Matriz de confusiÃ³n: VisualizaciÃ³n de errores de clasificaciÃ³n

---

### 2. Modelo de PredicciÃ³n de Churn

**Objetivo:** Identificar clientes en riesgo de abandonar el servicio calculando su probabilidad de churn.

**Features utilizadas:**
- `engagement_encoded`: Nivel de engagement del cliente (0-2: Bajo, Medio, Alto)
- `satisfaccion_encoded`: Nivel de satisfacciÃ³n (0-2: Bajo, Medio, Alto)
- `dias_ultima_compra`: DÃ­as transcurridos desde la Ãºltima transacciÃ³n
- `total_compras`: Suma total de compras en COP
- `promedio_compra`: Promedio de compra por transacciÃ³n
- `num_transacciones`: NÃºmero total de transacciones realizadas
- `std_compra`: DesviaciÃ³n estÃ¡ndar de las compras (variabilidad)

**Algoritmos comparados:**
- Random Forest Classifier
- Gradient Boosting Classifier

El script selecciona automÃ¡ticamente el modelo con mejor ROC-AUC.

**Target:** ClasificaciÃ³n binaria
- **Churn = 1**: Cliente en riesgo si cumple alguna de estas condiciones:
  - Engagement bajo
  - SatisfacciÃ³n baja
  - MÃ¡s de 90 dÃ­as sin comprar
- **No Churn = 0**: Cliente activo y saludable

**MÃ©tricas de evaluaciÃ³n:**
- ROC-AUC: Capacidad de discriminaciÃ³n del modelo
- Precision, Recall, F1-Score: Balance entre falsos positivos y negativos
- Matriz de confusiÃ³n
- Curva ROC
- DistribuciÃ³n de probabilidades

---

## ğŸš€ InstalaciÃ³n de Dependencias

Instala las librerÃ­as necesarias con pip:

\`\`\`bash
pip install pandas numpy scikit-learn matplotlib seaborn joblib
\`\`\`

**LibrerÃ­as requeridas:**
- `pandas`: ManipulaciÃ³n de datos
- `numpy`: Operaciones numÃ©ricas
- `scikit-learn`: Modelos de ML y mÃ©tricas
- `matplotlib` y `seaborn`: Visualizaciones
- `joblib`: SerializaciÃ³n de modelos

---

## â–¶ï¸ CÃ³mo Ejecutar el Entrenamiento

Desde la **raÃ­z del proyecto**, ejecuta:

\`\`\`bash
python ml/train_leads_and_churn.py
\`\`\`

**Proceso de entrenamiento:**

1. âœ… Carga los CSV desde `public/data/`:
   - `leads_historicos.csv`
   - `clientes_comportamiento.csv`
   - `clientes_transacciones.csv`

2. ğŸ”„ Realiza feature engineering automÃ¡tico:
   - Mapeo de variables categÃ³ricas
   - NormalizaciÃ³n con StandardScaler
   - AgregaciÃ³n de transacciones por cliente

3. ğŸ§ª Compara mÃºltiples algoritmos y selecciona el mejor

4. ğŸ“Š Genera visualizaciones:
   - Matriz de confusiÃ³n
   - Importancia de features
   - Curva ROC (solo para churn)
   - DistribuciÃ³n de probabilidades

5. ğŸ’¾ Guarda los modelos entrenados en `ml/models/`:
   - Modelos (.joblib)
   - Scalers (.joblib)
   - ConfiguraciÃ³n de features (.json)

**Manejo de errores:**

Si algÃºn CSV no se encuentra, el script imprime un mensaje claro y continÃºa con los otros modelos sin fallar:

\`\`\`
âš ï¸  No se encontrÃ³ public/data/leads_historicos.csv
   Por favor, asegÃºrate de que el archivo existe en public/data/
   Saltando entrenamiento del modelo de leads...
\`\`\`

---

## ğŸ“ Estructura de Archivos

\`\`\`
ml/
â”œâ”€â”€ train_leads_and_churn.py    # Script principal de entrenamiento
â”œâ”€â”€ utils.py                     # Funciones para predicciÃ³n
â”œâ”€â”€ README.md                    # Esta documentaciÃ³n
â””â”€â”€ models/                      # â¬‡ Generados despuÃ©s del entrenamiento
    â”œâ”€â”€ lead_quality_model.joblib
    â”œâ”€â”€ lead_quality_scaler.joblib
    â”œâ”€â”€ feature_config_leads.json
    â”œâ”€â”€ churn_model.joblib
    â”œâ”€â”€ churn_scaler.joblib
    â”œâ”€â”€ feature_config_churn.json
    â”œâ”€â”€ lead_quality_confusion_matrix.png
    â”œâ”€â”€ lead_quality_feature_importance.png
    â”œâ”€â”€ churn_confusion_matrix.png
    â”œâ”€â”€ churn_feature_importance.png
    â”œâ”€â”€ churn_roc_curve.png
    â””â”€â”€ churn_probability_distribution.png
\`\`\`

---

## ğŸ”§ Uso de los Modelos

### PredicciÃ³n Individual de Leads

\`\`\`python
from ml.utils import predict_lead_quality

lead_data = {
    'presupuesto': '10M-20M',
    'urgencia': 'Alta',
    'tipo_servicio': 'Desarrollo',
    'ciudad': 'BogotÃ¡'
}

result = predict_lead_quality(lead_data)

print(f"Calidad: {result['quality_label']}")  # 'caliente', 'tibio', o 'frÃ­o'
print(f"Score: {result['quality_score']:.1%}")  # Probabilidad de ser caliente
print(f"Probabilidades: {result['probabilities']}")  # Dict con todas las probabilidades
\`\`\`

**Salida esperada:**
\`\`\`
Calidad: caliente
Score: 87.3%
Probabilidades: {'frÃ­o': 0.05, 'tibio': 0.08, 'caliente': 0.87}
\`\`\`

---

### PredicciÃ³n Individual de Churn

\`\`\`python
from ml.utils import predict_churn

client_data = {
    'engagement': 'Bajo',
    'satisfaccion': 'Medio',
    'dias_ultima_compra': 120,
    'total_compras': 50000000,
    'promedio_compra': 10000000,
    'num_transacciones': 5,
    'std_compra': 2000000
}

result = predict_churn(client_data)

print(f"Probabilidad de churn: {result['churn_probability']:.1%}")
\`\`\`

**Salida esperada:**
\`\`\`
Probabilidad de churn: 78.5%
\`\`\`

---

### PredicciÃ³n en Batch (MÃºltiples Leads)

\`\`\`python
from ml.utils import batch_predict_leads

leads_list = [
    {'presupuesto': '10M-20M', 'urgencia': 'Alta', 'tipo_servicio': 'Desarrollo', 'ciudad': 'BogotÃ¡'},
    {'presupuesto': '5M-10M', 'urgencia': 'Media', 'tipo_servicio': 'ConsultorÃ­a', 'ciudad': 'MedellÃ­n'},
    {'presupuesto': 'MÃ¡s de 50M', 'urgencia': 'Inmediata', 'tipo_servicio': 'Infraestructura', 'ciudad': 'Cali'}
]

df_results = batch_predict_leads(leads_list)
print(df_results[['tipo_servicio', 'ciudad', 'predicted_quality_label', 'predicted_quality_score']])
\`\`\`

---

### PredicciÃ³n en Batch (MÃºltiples Clientes)

\`\`\`python
from ml.utils import batch_predict_churn

clients_list = [
    {'engagement': 'Bajo', 'satisfaccion': 'Bajo', 'dias_ultima_compra': 150, 
     'total_compras': 5000000, 'promedio_compra': 1000000, 'num_transacciones': 5, 'std_compra': 200000},
    {'engagement': 'Alto', 'satisfaccion': 'Alto', 'dias_ultima_compra': 15,
     'total_compras': 100000000, 'promedio_compra': 20000000, 'num_transacciones': 5, 'std_compra': 5000000}
]

df_churn = batch_predict_churn(clients_list)
print(df_churn[['engagement', 'satisfaccion', 'churn_probability']])
\`\`\`

---

## ğŸ“ˆ InterpretaciÃ³n de Resultados

### Lead Scoring

| Probabilidad | Etiqueta | AcciÃ³n Recomendada |
|--------------|----------|-------------------|
| â‰¥ 70% | ğŸ”¥ Caliente | Priorizar contacto inmediato |
| 40-70% | ğŸŸ¡ Tibio | Seguimiento regular |
| < 40% | ğŸ§Š FrÃ­o | Nurturing automatizado |

### Churn Prediction

| Probabilidad | Riesgo | AcciÃ³n Recomendada |
|--------------|--------|-------------------|
| â‰¥ 70% | ğŸš¨ Alto | IntervenciÃ³n urgente, llamada del account manager |
| 40-70% | âš ï¸ Medio | CampaÃ±a de re-engagement, oferta personalizada |
| < 40% | âœ… Bajo | Cliente saludable, mantener relaciÃ³n |

---

## ğŸ”„ Re-entrenamiento Recomendado

**CuÃ¡ndo re-entrenar los modelos:**

âœ… **Cada trimestre** como mÃ­nimo
âœ… Cuando se acumulen **>20% nuevos registros** en los CSV
âœ… Si el **rendimiento en producciÃ³n** disminuye notablemente
âœ… DespuÃ©s de **cambios en el modelo de negocio**

**Proceso de re-entrenamiento:**

\`\`\`bash
# 1. Actualiza los CSV en public/data/
# 2. Ejecuta el script de entrenamiento
python ml/train_leads_and_churn.py

# 3. Revisa las nuevas mÃ©tricas y visualizaciones en ml/models/
# 4. Si las mÃ©tricas son satisfactorias, los modelos estÃ¡n listos para producciÃ³n
\`\`\`

---

## âš™ï¸ ConfiguraciÃ³n Avanzada

Para ajustar hiperparÃ¡metros, edita `ml/train_leads_and_churn.py`:

**Modelo de Leads:**
\`\`\`python
RandomForestClassifier(
    n_estimators=100,        # NÃºmero de Ã¡rboles (mÃ¡s = mejor, pero mÃ¡s lento)
    max_depth=10,            # Profundidad mÃ¡xima (evita overfitting)
    min_samples_split=5,     # MÃ­nimo de muestras para split
    random_state=42,
    class_weight='balanced'  # Maneja desbalance de clases
)
\`\`\`

**Modelo de Churn:**
\`\`\`python
GradientBoostingClassifier(
    n_estimators=150,        # NÃºmero de Ã¡rboles
    learning_rate=0.1,       # Tasa de aprendizaje (0.01-0.3)
    max_depth=5,             # Profundidad de Ã¡rboles
    random_state=42
)
\`\`\`

**ConfiguraciÃ³n general:**
\`\`\`python
test_size=0.2  # ProporciÃ³n para testing (20%)
random_state=42  # Semilla para reproducibilidad
\`\`\`

---

## ğŸ› SoluciÃ³n de Problemas

**Error: "No se encontrÃ³ el archivo CSV"**
\`\`\`
âš ï¸  No se encontrÃ³ public/data/leads_historicos.csv
\`\`\`
âœ… SoluciÃ³n: Verifica que los CSV estÃ©n en `public/data/` desde la raÃ­z del proyecto

**Error: "FileNotFoundError: Modelo no encontrado"**
\`\`\`python
FileNotFoundError: Modelo no encontrado: ml/models/lead_quality_model.joblib
\`\`\`
âœ… SoluciÃ³n: Ejecuta primero el script de entrenamiento:
\`\`\`bash
python ml/train_leads_and_churn.py
\`\`\`

**Error: "KeyError en sample_dict"**
âœ… SoluciÃ³n: AsegÃºrate de que tu diccionario incluya todos los campos requeridos (ver ejemplos arriba)

---

## ğŸ¯ IntegraciÃ³n con Backend (Futuro)

Este mÃ³dulo estÃ¡ diseÃ±ado para integrarse fÃ¡cilmente con un backend Python (FastAPI):

\`\`\`python
# Ejemplo de API endpoint con FastAPI
from fastapi import FastAPI
from ml.utils import predict_lead_quality, predict_churn

app = FastAPI()

@app.post("/api/predict-lead-quality")
def predict_lead(lead: dict):
    return predict_lead_quality(lead)

@app.post("/api/predict-churn")
def predict_client_churn(client: dict):
    return predict_churn(client)
\`\`\`

---

## ğŸ“ Notas TÃ©cnicas

- âœ… Los modelos usan **StandardScaler** para normalizar features numÃ©ricas
- âœ… El modelo de leads maneja **desbalance de clases** con `class_weight='balanced'`
- âœ… Los CSV se leen desde `public/data/` usando **pathlib** para compatibilidad multiplataforma
- âœ… Todos los modelos incluyen **configuraciÃ³n de features** en JSON para reproducibilidad
- âœ… Las funciones incluyen **type hints** y **docstrings** completas para mejor documentaciÃ³n
- âœ… El cÃ³digo sigue **PEP 8** y mejores prÃ¡cticas de Python

---

## ğŸ“š Referencias

- [scikit-learn Documentation](https://scikit-learn.org/stable/)
- [Random Forest Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)
- [Gradient Boosting Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)
- [Understanding ROC Curves](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)

---

**Â¿Preguntas o problemas?** Contacta al equipo de Data Science ğŸ“§
